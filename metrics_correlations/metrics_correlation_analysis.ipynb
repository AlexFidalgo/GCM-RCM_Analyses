{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6ce4ec",
   "metadata": {},
   "source": [
    "# Metrics Correlation Analysis: GCM-RCM Error Metrics\n",
    "\n",
    "**Objective**: Analyze correlations between error metrics computed for climate model (GCM-RCM) pairs.\n",
    "\n",
    "**Data Structure**: For each combination of `(region, gridpoint, physical_variable, model)`, we have multiple error metrics (ACC, d, KGE, etc.). We compute correlations between these metrics to identify redundancy and orthogonal error facets.\n",
    "\n",
    "**Output**: Scatter plot matrix (pairplot), correlation heatmaps, and statistical summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510eb8fd",
   "metadata": {},
   "source": [
    "## 1. Project Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78911641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import os\n",
    "OUTPUT_DIR = \"./output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2607e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available regions. Set to None or empty list to include ALL regions. Analyze only France region: ['FR']\n",
    "REGIONS = ['SC']\n",
    "\n",
    "# Physical variables: 'ppt' (precipitation) or 'tas' (temperature). Set to None to include both. Only precipitation: ['ppt']\n",
    "PHYSICAL_VARIABLES = ['ppt']\n",
    "\n",
    "# Metric abbreviations to include in the correlation analysis. None = all metrics; or specify like ['ACC', 'd', 'KGE (2009)', 'BM']\n",
    "METRIC_ABBREVIATIONS = ['H10 (MAHE)', 'd', 'dr', 'NED', 'MV', 'KGE (2009)']\n",
    "\n",
    "# Optional filters for RCM and GCM IDs. None or [] = include all.\n",
    "# RCM_IDS = None  # e.g., [1, 2, 3]\n",
    "# GCM_IDS = None  # e.g., [3, 4]\n",
    "RCM_IDS = [1,2,5,6,8,11,12]\n",
    "GCM_IDS = [3,7,8]\n",
    "\n",
    "# Correlation method: 'pearson', 'spearman', or 'kendall'\n",
    "CORRELATION_METHOD = 'pearson'\n",
    "\n",
    "print(f\"Regions: {REGIONS if REGIONS else 'ALL'}\")\n",
    "print(f\"Physical Variables: {PHYSICAL_VARIABLES if PHYSICAL_VARIABLES else 'ALL'}\")\n",
    "print(f\"Metric Abbreviations: {METRIC_ABBREVIATIONS if METRIC_ABBREVIATIONS else 'ALL'}\")\n",
    "print(f\"RCM IDs: {RCM_IDS if RCM_IDS else 'ALL'}\")\n",
    "print(f\"GCM IDs: {GCM_IDS if GCM_IDS else 'ALL'}\")\n",
    "print(f\"Correlation Method: {CORRELATION_METHOD}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c263f41",
   "metadata": {},
   "source": [
    "## 2. Load Data from Database\n",
    "\n",
    "We'll query the error and metrics tables from the database (as described in the SQL schema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') \n",
    "from utils import get_db_connection\n",
    "engine = get_db_connection()\n",
    "conn = engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22aec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_clauses = []\n",
    "\n",
    "if REGIONS is not None and len(REGIONS) > 0:\n",
    "    regions_str = \"', '\".join(REGIONS)\n",
    "    where_clauses.append(f\"error.region IN ('{regions_str}')\")\n",
    "\n",
    "if PHYSICAL_VARIABLES is not None and len(PHYSICAL_VARIABLES) > 0:\n",
    "    vars_str = \"', '\".join(PHYSICAL_VARIABLES)\n",
    "    where_clauses.append(f\"error.physical_variable IN ('{vars_str}')\")\n",
    "\n",
    "if METRIC_ABBREVIATIONS is not None and len(METRIC_ABBREVIATIONS) > 0:\n",
    "    metrics_str = \"', '\".join(METRIC_ABBREVIATIONS)\n",
    "    where_clauses.append(f\"metrics.metric_name IN ('{metrics_str}')\")\n",
    "\n",
    "if RCM_IDS is not None and len(RCM_IDS) > 0:\n",
    "    rcm_str = \", \".join(str(x) for x in RCM_IDS)\n",
    "    where_clauses.append(f\"error.rcm_id IN ({rcm_str})\")\n",
    "\n",
    "if GCM_IDS is not None and len(GCM_IDS) > 0:\n",
    "    gcm_str = \", \".join(str(x) for x in GCM_IDS)\n",
    "    where_clauses.append(f\"error.gcm_id IN ({gcm_str})\")\n",
    "\n",
    "where_clause = \" AND \".join(where_clauses)\n",
    "if where_clause:\n",
    "    where_clause = f\"WHERE {where_clause}\"\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    error.region,\n",
    "    error.gridpoint,\n",
    "    error.physical_variable,\n",
    "    error.model,\n",
    "    error.rcm_id,\n",
    "    error.gcm_id,\n",
    "    error.metric_id,\n",
    "    metrics.metric_name,\n",
    "    error.mat_vector\n",
    "FROM \n",
    "    error \n",
    "LEFT JOIN \n",
    "    metrics ON metrics.id = error.metric_id\n",
    "{where_clause}\n",
    "\"\"\"\n",
    "\n",
    "df_raw = pd.read_sql_query(query, conn)\n",
    "print(f\"✓ Data loaded: {len(df_raw)} rows\")\n",
    "print(f\"  Columns: {list(df_raw.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df_raw.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0abb16",
   "metadata": {},
   "source": [
    "## 3. Data Filtering & Preprocessing\n",
    "\n",
    "Apply the filters to select the region(s), physical variable(s), and metric(s) of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "print(f\"✓ Data retrieved (pre-filtered by database query):\")\n",
    "print(f\"  Total rows: {len(df)}\")\n",
    "print(f\"  Regions: {sorted(df['region'].unique())}\")\n",
    "print(f\"  Physical variables: {sorted(df['physical_variable'].unique())}\")\n",
    "print(f\"  Unique metrics: {df['metric_name'].nunique()}\")\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Metrics: {sorted(df['metric_name'].unique())}\")\n",
    "print(f\"Unique models: {df['model'].nunique()}\")\n",
    "print(f\"Unique gridpoints: {df['gridpoint'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f50888",
   "metadata": {},
   "source": [
    "## 4. Create Pivot Table for Correlation Analysis\n",
    "\n",
    "Transform the data so that each row represents a unique `(region, gridpoint, physical_variable, model)` grouping,  \n",
    "and each column is a metric. This structure allows us to compute correlations between metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c2b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grouping key for (region, gridpoint, physical_variable, model)\n",
    "df['group_key'] = df.apply(\n",
    "    lambda row: f\"{row['region']}_{row['gridpoint']}_{row['physical_variable']}_{row['model']}\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Pivot: rows are group_keys, columns are metric names, values are error values\n",
    "pivot_df = df.pivot_table(\n",
    "    index='group_key',\n",
    "    columns='metric_name',\n",
    "    values='mat_vector',\n",
    "    aggfunc='first'  # Should be unique per group_key, but just in case\n",
    ")\n",
    "\n",
    "print(f\"✓ Pivot table created:\")\n",
    "print(f\"  Shape: {pivot_df.shape}\")\n",
    "print(f\"  Rows (unique group_keys): {pivot_df.shape[0]}\")\n",
    "print(f\"  Columns (metrics): {pivot_df.shape[1]}\")\n",
    "print(f\"\\nMetrics in pivot table:\")\n",
    "print(pivot_df.columns.tolist())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(pivot_df.head())\n",
    "\n",
    "print(f\"\\nMissing values per metric:\")\n",
    "print(pivot_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e89be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df_clean = pivot_df.dropna()\n",
    "\n",
    "print(f\"  Original: {pivot_df.shape[0]} rows\")\n",
    "print(f\"  After dropna: {pivot_df_clean.shape[0]} rows\")\n",
    "print(f\"  Rows removed: {pivot_df.shape[0] - pivot_df_clean.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98effbe0",
   "metadata": {},
   "source": [
    "## 5. Compute Pairwise Correlations\n",
    "\n",
    "Calculate correlation coefficients between all pairs of metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = pivot_df_clean.corr(method=CORRELATION_METHOD)\n",
    "\n",
    "print(f\"✓ Correlation matrix computed ({CORRELATION_METHOD}):\")\n",
    "print(f\"  Shape: {corr_matrix.shape}\")\n",
    "print(f\"\\nCorrelation Matrix:\")\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17950586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_corr_with_pvalues(df, method='pearson'):\n",
    "    \"\"\"Compute pairwise correlations and p-values.\"\"\"\n",
    "    cols = df.columns\n",
    "    n_cols = len(cols)\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_cols):\n",
    "        for j in range(i + 1, n_cols):\n",
    "            metric1 = cols[i]\n",
    "            metric2 = cols[j]\n",
    "            \n",
    "            if method == 'pearson':\n",
    "                corr, pval = pearsonr(df[metric1], df[metric2])\n",
    "            elif method == 'spearman':\n",
    "                corr, pval = spearmanr(df[metric1], df[metric2])\n",
    "            elif method == 'kendall':\n",
    "                corr, pval = kendalltau(df[metric1], df[metric2])\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown method: {method}\")\n",
    "            \n",
    "            results.append({\n",
    "                'Metric 1': metric1,\n",
    "                'Metric 2': metric2,\n",
    "                'Correlation': corr,\n",
    "                'P-value': pval,\n",
    "                'N': len(df)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92426573",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_df = pairwise_corr_with_pvalues(pivot_df_clean, method=CORRELATION_METHOD)\n",
    "\n",
    "pairwise_df['Abs_Corr'] = pairwise_df['Correlation'].abs()\n",
    "pairwise_df = pairwise_df.sort_values('Abs_Corr', ascending=False).drop('Abs_Corr', axis=1)\n",
    "\n",
    "print(f\"\\n✓ Pairwise correlations ({len(pairwise_df)} pairs):\")\n",
    "print(pairwise_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c95b482",
   "metadata": {},
   "source": [
    "- $H_0$: zero correlation  \n",
    "- $H_1$: non-zero correlation\n",
    "\n",
    "This **p-value** is the two-sided probability of observing a correlation at least as extreme as the measured one under the null hypothesis.\n",
    "\n",
    "Assumptions\n",
    "- **Pearson**: assumes a linear relationship and (approximately) bivariate normality.  \n",
    "- **Spearman** / **Kendall**: rank-based (nonparametric), less sensitive to outliers or non-normality.\n",
    "\n",
    "Can also be seen as association:\n",
    "- $H_0$: The population correlation is zero (no association)\n",
    "- $H_1$: The population correlation is non-zero (association exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ed689",
   "metadata": {},
   "source": [
    "## 6. Scatter Plot Matrix (Pairplot)\n",
    "\n",
    "Generate a pairplot to visualize relationships between metrics (similar to the attached image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a434fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "g = sns.pairplot(\n",
    "    pivot_df_clean,\n",
    "    diag_kind='hist',\n",
    "    plot_kws={'alpha': 0.6, 's': 30},\n",
    "    diag_kws={'bins': 30, 'edgecolor': 'k', 'alpha': 0.7}\n",
    ")\n",
    "\n",
    "def add_correlation_annotations(g, corr_matrix, pairwise_df):\n",
    "    \"\"\"Add correlation values with p-value based significance markers to upper triangle of pairplot.\"\"\"\n",
    "    for i, ax_row in enumerate(g.axes):\n",
    "        for j, ax in enumerate(ax_row):\n",
    "            if i < j:\n",
    "                col_i = g.data.columns[i]\n",
    "                col_j = g.data.columns[j]\n",
    "                corr_val = corr_matrix.loc[col_i, col_j]\n",
    "                \n",
    "                pair_row = pairwise_df[\n",
    "                    ((pairwise_df['Metric 1'] == col_i) & (pairwise_df['Metric 2'] == col_j)) |\n",
    "                    ((pairwise_df['Metric 1'] == col_j) & (pairwise_df['Metric 2'] == col_i))\n",
    "                ]\n",
    "                \n",
    "                if not pair_row.empty:\n",
    "                    pval = pair_row.iloc[0]['P-value']\n",
    "                    sig_marker = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \"ns\"\n",
    "                else:\n",
    "                    sig_marker = \"?\"\n",
    "                \n",
    "                ax.text(\n",
    "                    0.5, 0.5,\n",
    "                    f'{corr_val:.2f}{sig_marker}',\n",
    "                    transform=ax.transAxes,\n",
    "                    ha='center', va='center',\n",
    "                    fontsize=12, fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "                )\n",
    "                ax.set_title('')\n",
    "\n",
    "add_correlation_annotations(g, corr_matrix, pairwise_df)\n",
    "\n",
    "plt.suptitle(\n",
    "    f'Metrics Correlation Analysis - Scatter Plot Matrix\\n'\n",
    "    f'Region(s): {REGIONS if REGIONS else \"ALL\"} | ' \n",
    "    f'Variable(s): {PHYSICAL_VARIABLES if PHYSICAL_VARIABLES else \"ALL\"} | ' \n",
    "    f'RCM(s): {RCM_IDS if RCM_IDS else \"ALL\"} | ' \n",
    "    f'GCM(s): {GCM_IDS if GCM_IDS else \"ALL\"} | ' \n",
    "    f'Method: {CORRELATION_METHOD}',\n",
    "    fontsize=14, y=1.00\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "output_file = f\"{OUTPUT_DIR}/pairplot_{CORRELATION_METHOD}.png\"\n",
    "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Pairplot saved to: {output_file}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8f7cc",
   "metadata": {},
   "source": [
    "The `**` symbols in the pairplot are significance markers that indicate the statistical significance of the correlation coefficients displayed in the upper triangle of the plot.\n",
    "\n",
    "- `***` = p-value < 0.001 (highly significant)\n",
    "- `**` = p-value < 0.01 (very significant)\n",
    "- `*` = p-value < 0.05 (significant)\n",
    "- ns = not significant (p-value ≥ 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91294687",
   "metadata": {},
   "source": [
    "## 7. Correlation Heatmap\n",
    "\n",
    "Visualize the correlation matrix as a heatmap with hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f584db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.clustermap(\n",
    "    corr_matrix,\n",
    "    cmap='RdBu_r',\n",
    "    center=0,\n",
    "    vmin=-1, vmax=1,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cbar_kws={'label': f'{CORRELATION_METHOD.capitalize()} Correlation'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray'\n",
    ")\n",
    "\n",
    "plt.suptitle(\n",
    "    f'Hierarchical Correlation Heatmap ({CORRELATION_METHOD})\\n'\n",
    "    f'Region(s): {REGIONS if REGIONS else \"ALL\"} | Variable(s): {PHYSICAL_VARIABLES if PHYSICAL_VARIABLES else \"ALL\"} | RCM(s): {RCM_IDS if RCM_IDS else \"ALL\"} | GCM(s): {GCM_IDS if GCM_IDS else \"ALL\"}',\n",
    "    fontsize=14, y=0.98\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "output_file = f\"{OUTPUT_DIR}/heatmap_clustered_{CORRELATION_METHOD}.png\"\n",
    "plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Heatmap saved to: {output_file}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d421b59",
   "metadata": {},
   "source": [
    "## 8. Export Results\n",
    "\n",
    "Save correlation matrices and pairwise correlations to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save correlation matrix to CSV\n",
    "corr_matrix.to_csv(f\"{OUTPUT_DIR}/correlation_matrix_{CORRELATION_METHOD}.csv\")\n",
    "print(f\"✓ Correlation matrix saved to: {OUTPUT_DIR}/correlation_matrix_{CORRELATION_METHOD}.csv\")\n",
    "\n",
    "# Save pairwise correlations to CSV\n",
    "pairwise_df.to_csv(f\"{OUTPUT_DIR}/pairwise_correlations_{CORRELATION_METHOD}.csv\", index=False)\n",
    "print(f\"✓ Pairwise correlations saved to: {OUTPUT_DIR}/pairwise_correlations_{CORRELATION_METHOD}.csv\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Metric': corr_matrix.columns,\n",
    "    'Mean': pivot_df_clean.mean(),\n",
    "    'Std': pivot_df_clean.std(),\n",
    "    'Min': pivot_df_clean.min(),\n",
    "    'Max': pivot_df_clean.max(),\n",
    "})\n",
    "summary_stats.to_csv(f\"{OUTPUT_DIR}/metrics_summary_statistics.csv\", index=False)\n",
    "print(f\"✓ Summary statistics saved to: {OUTPUT_DIR}/metrics_summary_statistics.csv\")\n",
    "\n",
    "# Save analysis metadata\n",
    "metadata = {\n",
    "    'Analysis Date': pd.Timestamp.now(),\n",
    "    'Correlation Method': CORRELATION_METHOD,\n",
    "    'Regions': str(REGIONS),\n",
    "    'Physical Variables': str(PHYSICAL_VARIABLES),\n",
    "    'RCM IDs': str(RCM_IDS),\n",
    "    'GCM IDs': str(GCM_IDS),\n",
    "    'Metric Abbreviations': str(METRIC_ABBREVIATIONS),\n",
    "    'Number of Rows': pivot_df_clean.shape[0],\n",
    "    'Number of Metrics': pivot_df_clean.shape[1],\n",
    "    'Metrics': ', '.join(pivot_df_clean.columns)\n",
    "}\n",
    "\n",
    "metadata_df = pd.DataFrame(list(metadata.items()), columns=['Parameter', 'Value'])\n",
    "metadata_df.to_csv(f\"{OUTPUT_DIR}/analysis_metadata.csv\", index=False)\n",
    "print(f\"✓ Analysis metadata saved to: {OUTPUT_DIR}/analysis_metadata.csv\")\n",
    "\n",
    "print(f\"\\n✓ All results exported to: {OUTPUT_DIR}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6a6e4",
   "metadata": {},
   "source": [
    "## 9. Summary & Insights\n",
    "\n",
    "Summary of the correlation analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 90)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\nData Summary:\")\n",
    "print(f\"  Total rows analyzed: {pivot_df_clean.shape[0]}\")\n",
    "print(f\"  Number of metrics: {pivot_df_clean.shape[1]}\")\n",
    "print(f\"  Correlation method: {CORRELATION_METHOD}\")\n",
    "\n",
    "print(f\"\\nMetrics included:\")\n",
    "for i, metric in enumerate(pivot_df_clean.columns, 1):\n",
    "    print(f\"  {i}. {metric}\")\n",
    "\n",
    "print(f\"\\nAll Pairwise Correlations (sorted by absolute correlation value):\")\n",
    "print(\"-\" * 90)\n",
    "# Create a formatted display with all correlations and p-values\n",
    "display_df = pairwise_df.copy()\n",
    "display_df['Significance'] = display_df['P-value'].apply(\n",
    "    lambda p: \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"ns\"\n",
    ")\n",
    "display_df = display_df[['Metric 1', 'Metric 2', 'Correlation', 'P-value', 'Significance']]\n",
    "print(display_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 90)\n",
    "print(f\"Significance levels (α = 0.05):\")\n",
    "sig_count = (pairwise_df['P-value'] < 0.05).sum()\n",
    "print(f\"  Significant correlations: {sig_count} / {len(pairwise_df)} ({100*sig_count/len(pairwise_df):.1f}%)\")\n",
    "\n",
    "print(\"\\nNote: *** p<0.001, ** p<0.01, * p<0.05, ns = not significant\")\n",
    "print(\"=\" * 90)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
